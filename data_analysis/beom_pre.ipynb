{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 김기범 전치리 코드 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45678, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. add predefined news category"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df['text'][:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df['input_text'][:10] + \" [SEP] \" + train_df['predefined_news_category'][:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. AI HUB 뉴스 기사 데이터 가져오기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from glob import glob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ai_hub_017 = glob('../data/ai_hub_017/*.json')\n",
    "ai_hub_017"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import json\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for path in ai_hub_017:\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            js = json.loads(f.read())\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    new_df = pd.json_normalize(js['data'])\n",
    "\n",
    "    df = pd.concat([df, new_df], axis=0)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df['doc_class.code'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use_classes = ['정치', '경제', '사회', '문화', '스포츠', 'IT과학', '국제']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df2 = df[(df['doc_class.code'] != '지역') & (df['doc_class.code'] != '기타')][['doc_id', 'doc_title', 'doc_class.code']]\n",
    "df2.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df2.drop_duplicates()\n",
    "\n",
    "df2.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df2['doc_class.code'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df2['doc_class.code'] = df2['doc_class.code'].replace('국제', '세계')\n",
    "df2['doc_class.code'] = df2['doc_class.code'].replace('문화', '생활문화')\n",
    "\n",
    "df2['doc_class.code'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df.columns, df2.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label2num = {\n",
    "    label: i for i, label in enumerate(['정치', '경제', '사회', '생활문화', '세계', 'IT과학', '스포츠'])\n",
    "}\n",
    "label2num"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df2.columns = ['ID', 'input_text', 'label_text']\n",
    "df2['target'] = df2['label_text'].apply(lambda x: label2num[x])\n",
    "\n",
    "df2.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(pd.concat([train_df, df2], axis=0).shape)\n",
    "print(pd.concat([train_df, df2], axis=0).drop_duplicates(subset=['input_text']).shape)\n",
    "print(pd.concat([train_df, df2], axis=0).drop_duplicates(subset=['input_text', 'target']).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df2.to_csv('../data/ai_hub_017.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. AI HUB 낚시 기사성 뉴스 데이터"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ai_hub_146_val_path_list = glob(\"../data/ai_hub_146_val/*/*.json\")\n",
    "len(ai_hub_146_val_path_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "id = []\n",
    "category = []\n",
    "title = []\n",
    "\n",
    "for path in ai_hub_146_val_path_list:\n",
    "    new_df = pd.read_json(path)\n",
    "\n",
    "    id.append(new_df.loc['newsID']['sourceDataInfo'])\n",
    "    category.append(new_df.loc['newsCategory']['sourceDataInfo'])\n",
    "    title.append(new_df.loc['newsTitle']['sourceDataInfo'])\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['ID'] = id\n",
    "df['input_text'] = category\n",
    "df['label_text'] = title\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.columns = ['ID', 'label_text', 'input_text']\n",
    "df['label_text'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df['label_text'] = df['label_text'].replace(r'&', '', regex=True)\n",
    "df['label_text'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df2['target'] = df2['label_text'].apply(lambda x: label2num[x])\n",
    "df2.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df2.to_csv('../data/ai_hub_146_val.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. AI HUB 데이터끼리 합치기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ai_hub_017 = pd.read_csv('../data/ai_hub_017.csv')\n",
    "ai_hub_146 = pd.read_csv('../data/ai_hub_146_val.csv')\n",
    "ai_hub = pd.concat([ai_hub_017, ai_hub_146], axis=0)\n",
    "\n",
    "ai_hub.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ai_hub.drop_duplicates(subset=['input_text', 'target'], inplace=True)\n",
    "ai_hub.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ai_hub[ai_hub.duplicated(subset=['input_text'], keep=False)].sort_values(by='input_text')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "del_duplicate_index = [29288, 29764, 29406, 29750, 29442, 29773, 54108, 29626, 29450, 10340, 25707, 42812, 11774, 29751,\n",
    "                       29443, 30159, 30137, 29813, 24469, 40823, 29762, 82929, 79340, 29810, 30135, 29801, 29752, 18799, 30136]\n",
    "\n",
    "ai_hub.drop(del_duplicate_index, axis=0, inplace=True)\n",
    "ai_hub.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ai_hub['target'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_count = [722, 1348, 3701, 1369, 835, 554, 578]\n",
    "\n",
    "for idx, count in enumerate(test_count):\n",
    "    print(idx, \">\", round(count / 9107 * 100, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ai_hub['target'].value_counts(normalize=True) * 100).sort_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ai_hub.to_csv('../data/ai_hub_original.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ai_hub 분포 맞추기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 최종 데이터셋 생성"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_no_g2p = pd.read_csv('../data/train_No_G2P.csv')\n",
    "label_error_detecting = pd.read_csv('../data/label_error_detecting.csv')\n",
    "\n",
    "train_no_g2p.shape, label_error_detecting.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label_error_detecting.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label_error_detecting.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label_error_detecting['정답'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_no_g2p.drop(label_error_detecting[label_error_detecting['정답'] == False].index, axis=0, inplace=True)\n",
    "train_no_g2p.shape, 47049 - 193"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_no_g2p[train_no_g2p.duplicated(subset=['ID', 'input_text'])].shape, 1365 + 198"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 데이터셋 뒤섞기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df.sample(frac=1, random_state=42, axis=0).head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Korean Easy Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: koeda in /opt/conda/lib/python3.8/site-packages (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.19.4 in /opt/conda/lib/python3.8/site-packages (from koeda) (1.23.1)\n",
      "Requirement already satisfied: konlpy>=0.5.2 in /opt/conda/lib/python3.8/site-packages (from koeda) (0.6.0)\n",
      "Requirement already satisfied: tweepy==3.10.0 in /opt/conda/lib/python3.8/site-packages (from koeda) (3.10.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /opt/conda/lib/python3.8/site-packages (from tweepy==3.10.0->koeda) (2.30.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from tweepy==3.10.0->koeda) (1.3.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.8/site-packages (from tweepy==3.10.0->koeda) (1.15.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from konlpy>=0.5.2->koeda) (1.4.1)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /opt/conda/lib/python3.8/site-packages (from konlpy>=0.5.2->koeda) (4.9.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from JPype1>=0.7.0->konlpy>=0.5.2->koeda) (23.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->tweepy==3.10.0->koeda) (3.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy==3.10.0->koeda) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy==3.10.0->koeda) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy==3.10.0->koeda) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy==3.10.0->koeda) (2020.12.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy==3.10.0->koeda) (1.7.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install koeda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from koeda import EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda = EDA(\n",
    "    morpheme_analyzer=\"Okt\", alpha_sr=0.3, alpha_ri=0.3, alpha_rs=0.3, prob_rd=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "before >> 유튜브 내달 2일까지 크리에이터 지원 공간 운영\n",
      "after >> 유튜브운영내달 2일까지 크리에이터 공간 지원\n",
      "==========\n",
      "before >> 어버이날 막따가 흐려저…남부지방 여튼 황사\n",
      "after >> 막따가 …지방 튼 황사\n",
      "==========\n",
      "before >> 내년부터 국가RD 평가 때 논문건수는 반영 않는다\n",
      "after >> 내년부터 국가RD 평가 때 논문건수는 감응 않는다\n",
      "==========\n",
      "before >> 김명자 신임 과총 회장 원로와 젊은 과학자 지혜 모을 것\n",
      "after >> 김명자 신임 회장 원로와 모을\n",
      "==========\n",
      "before >> 회새긴간 작까 김동시 걍심꼬백 뜽 새 소설집 뚜권 출간\n",
      "after >> 작까 동시 뜽 새 소설집 뚜 출간\n",
      "==========\n",
      "before >> 야외서 생방송 하세요…액션캠 전용 요금제 잇따라\n",
      "after >> 야외서 생방송하세요 액션캠 전용 요금제…잇따라\n",
      "==========\n",
      "before >> 월드컵 태극전사 16강 전초기지 레오강 입성종합\n",
      "after >> 월드컵 16강 전초기지 강 입성\n",
      "==========\n",
      "before >> 미세먼지 속 출근길\n",
      "after >> 미세먼지 정신 출근길\n",
      "==========\n",
      "before >> 왓츠앱稅 230원에 성난 레바논 민심…총리사퇴로 이어져종합2보\n",
      "after >> 왓츠앱稅 230원에 성난 레바논 거부 민심… 사절 총리 관리 사퇴로 정경 이어져종합2보\n",
      "==========\n",
      "before >> 베트남 경제 고성장 지속…2분기 GDP 6.71% 성장\n",
      "after >> 베트남 경제 고성장 지속…2분 성기 기 GDP 6.71% 급속도 고생 성장\n"
     ]
    }
   ],
   "source": [
    "for s in train_df['text'][:10]:\n",
    "    change = eda(s)\n",
    "\n",
    "    print(\"=\"*10)\n",
    "    print(\"before >>\", s)\n",
    "    print(\"after >>\", change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         유튜브 내달 2일까지 크리에이터 지원 공간 운영\n",
       "1            어버이날 막따가 흐려저…남부지방 여튼 황사\n",
       "2        내년부터 국가RD 평가 때 논문건수는 반영 않는다\n",
       "3    김명자 신임 과총 회장 원로와 젊은 과학자 지혜 모을 것\n",
       "4     회새긴간 작까 김동시 걍심꼬백 뜽 새 소설집 뚜권 출간\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['text'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['유튜브 까지 크리에이터 공간 운영',\n",
       " '어버이날 막따가 흐려저남부지방 여튼 황사',\n",
       " '내년부터 국가RD 평가 때 논문건수 반영 않는다',\n",
       " '김명자 신임 과총 회장 원로와 젊은 과학자 지혜 모을 것',\n",
       " '회새긴간 작까 김동시 걍심꼬백 뜽 새 소설집 권 출간']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from koeda import RD\n",
    "\n",
    "func = RD(\"Okt\")\n",
    "sen_after_RD = func(train_df['text'].to_list(), 0.1)\n",
    "\n",
    "sen_after_RD[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['유튜브크리에이터내달 2일까지 지원 공간 운영',\n",
       " '막따가 흐려저…남부지방 여튼어버이날황사',\n",
       " '부터 국가RD 평가 때 논문건수는 반영내년않는다',\n",
       " '김명자 신임 회장 원로와 젊은 과학자과총지혜 모을 것',\n",
       " '회새긴간 작까 김동시 걍심꼬백간뜽 새 소설집 뚜권 출']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from koeda import RS\n",
    "\n",
    "func = RS(\"Okt\")\n",
    "sen_after_RS = func(train_df['text'].to_list(), 0.1)\n",
    "\n",
    "sen_after_RS[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['findall'] = train_df['text'].str.findall(pat='[^A-Za-z0-9가-힣\\s]{1,9999}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'text', 'target', 'url', 'date', 'findall'], dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           []\n",
       "1          […]\n",
       "2           []\n",
       "3           []\n",
       "4           []\n",
       "         ...  \n",
       "45673      [·]\n",
       "45674      […]\n",
       "45675    [...]\n",
       "45676       []\n",
       "45677    [...]\n",
       "Name: findall, Length: 45678, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['findall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_words = set([word for row in train_df['findall'] for word in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              유튜브 내달 2일까지 크리에이터 지원 공간 운영\n",
       "1                 어버이날 맑다가 흐려져…남부지방 옅은 황사\n",
       "2             내년부터 국가RD 평가 때 논문건수는 반영 않는다\n",
       "3         김명자 신임 과총 회장 원로와 젊은 과학자 지혜 모을 것\n",
       "4          회색인간 작가 김동식 양심고백 등 새 소설집 2권 출간\n",
       "                       ...               \n",
       "45673        사우디 아람코 주요 석유시설·유전 드론 공격에 화재\n",
       "45674      박기원 감독 눈치 보지 말고…비예나 눈치 본 건 아닌데\n",
       "45675    아시안게임 첫 경기 앞둔 라건아 인도네시아 팬이라도 ...\n",
       "45676       트럼프 미중 무역협상 1단계 합의 서명식 가질 것종합\n",
       "45677    극적 역전승 도로공사 GS칼텍스 꺾고 2년 연속 챔프...\n",
       "Name: text, Length: 45678, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/train_spelling.csv')\n",
    "\n",
    "train_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        유튜브 내달 2일까지 크리에이터 지원 공간 운영\n",
       "1                         어버이날 맑다가 흐려져 … 남부지방 옅은 황사\n",
       "2                       내년부터 국가RD 평가 때 논문건수는 반영 않는다\n",
       "3                   김명자 신임 과총 회장 원로와 젊은 과학자 지혜 모을 것\n",
       "4                    회색인간 작가 김동식 양심고백 등 새 소설집 2권 출간\n",
       "                            ...                    \n",
       "45673                사우디 아람코 주요 석유시설 · 유전 드론 공격에 화재\n",
       "45674              박기원 감독 눈치 보지 말고 … 비예나 눈치 본 건 아닌데\n",
       "45675    아시안게임 첫 경기 앞둔 라건아 인도네시아 팬이라도    .  .   .  \n",
       "45676                 트럼프 미중 무역협상 1단계 합의 서명식 가질 것종합\n",
       "45677    극적 역전승 도로공사 GS칼텍스 꺾고 2년 연속 챔프   .  .   .  \n",
       "Name: text, Length: 45678, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in sorted(list(special_words), key=lambda x: len(x), reverse=True):\n",
    "    train_df['text'] = train_df['text'].str.replace(word, f\" {word} \")\n",
    "\n",
    "train_df['text'] = train_df['text'].str.replace('[\\s]{2, 9999}', \" \")\n",
    "train_df['text']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. label error 잡기 위해 target에 따른 단어 빈도 수 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train_spelling_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== IT과학 =====\n",
      "15078\n",
      "상위 20개\n",
      "[('출시', 397), ('5G', 359), ('KT', 307), ('개발', 262), ('AI', 207), ('네이버', 179), ('게시판', 175), ('서비스', 173), ('삼성', 169), ('스마트폰', 162), ('SKT', 154), ('LG', 153), ('첫', 150), ('공개', 150), ('기술', 129), ('국내', 127), ('SK텔레콤', 105), ('세계', 97), ('모바일', 92), ('LG전자', 91)]\n",
      "하위 20개\n",
      "[('야외서', 1), ('하세요…액션캠', 1), ('나노분야', 1), ('학술지', 1), ('컨버전스', 1), ('SCIE', 1), ('행정절차', 1), ('완료…이통3사', 1), ('윌림', 1), ('공모전서', 1), ('퀀텀닷OLED', 1), ('상품촬영', 1), ('카메라앱', 1), ('스토어카메라', 1), ('왔나', 1), ('V낸드·LG디스플레이', 1), ('둘러보는', 1), ('마니아층', 1), ('사로잡았다', 1), ('인기몰이종합', 1)]\n",
      "===== 경제 =====\n",
      "16480\n",
      "상위 20개\n",
      "[('영업익', 263), ('코스피', 258), ('특징주', 239), ('작년', 226), ('1분기', 158), ('출시', 156), ('게시판', 155), ('증가', 148), ('규모', 147), ('2분기', 144), ('실적', 143), ('결정', 142), ('그래픽', 127), ('3분기', 121), ('올해', 121), ('감소', 120), ('등', 120), ('만에', 105), ('국내', 104), ('하락', 103)]\n",
      "하위 20개\n",
      "[('1천706억원…마케팅', 1), ('日규제', 1), ('피해보다', 1), ('불확실성이', 1), ('6.8%↑…증가세', 1), ('매입임대주택', 1), ('분란', 1), ('조짐…LG전자', 1), ('흔들기', 1), ('추락…최근', 1), ('4.86%', 1), ('미국특허', 1), ('LG전자·삼성전자', 1), ('1∼2위', 1), ('명성티엔에스·삼성스팩2호', 1), ('1900∼2400선', 1), ('39사단', 1), ('유니시티', 1), ('청약에', 1), ('20만명', 1)]\n",
      "===== 사회 =====\n",
      "17479\n",
      "상위 20개\n",
      "[('게시판', 242), ('등', 113), ('사장', 104), ('KBS', 93), ('개최', 92), ('첫', 73), ('방통위', 70), ('MBC', 68), ('네이버', 63), ('회장', 61), ('의혹', 59), ('KT', 58), ('전', 58), ('논란', 53), ('지원', 52), ('검찰', 51), ('선정', 50), ('것', 47), ('중', 47), ('한국', 44)]\n",
      "하위 20개\n",
      "[('국가RD', 1), ('논문건수는', 1), ('않는다', 1), ('원로와', 1), ('과학자', 1), ('지혜', 1), ('모을', 1), ('강릉서', 1), ('산불현장처럼', 1), ('정경두에', 1), ('안보지원사', 1), ('연구비관리시스템', 1), ('2개로', 1), ('통합한다', 1), ('SK텔레콤안양시', 1), ('모빌리티·스마트시티', 1), ('응시', 1), ('127만명…경제비용', 1), ('수조원', 1), ('당국의', 1)]\n",
      "===== 생활문화 =====\n",
      "17007\n",
      "상위 20개\n",
      "[('신간', 596), ('여행', 190), ('주말', 169), ('N', 161), ('전국', 142), ('게시판', 128), ('개막', 118), ('날씨', 106), ('개최', 102), ('첫', 99), ('최고', 98), ('비', 98), ('출간', 86), ('베스트셀러', 83), ('미세먼지', 78), ('충북', 78), ('공연', 76), ('서울', 73), ('눈', 71), ('등', 69)]\n",
      "하위 20개\n",
      "[('어버이날', 1), ('흐려져…남부지방', 1), ('회색인간', 1), ('양심고백', 1), ('기둥', 1), ('100권의', 1), ('잡지를', 1), ('저녁까지', 1), ('비·강한', 1), ('바람…낮', 1), ('황사·미세먼지', 1), ('주말…나들이객', 1), ('목양면', 1), ('방화', 1), ('전말기', 1), ('빠져', 1), ('않기', 1), ('강풍·영하권', 1), ('날씨…오후부터', 1), ('비까지', 1)]\n",
      "===== 세계 =====\n",
      "24160\n",
      "상위 20개\n",
      "[('美', 574), ('이란', 543), ('트럼프', 477), ('中', 357), ('터키', 245), ('대통령', 224), ('시리아', 224), ('사망', 210), ('홍콩', 175), ('중국', 174), ('것', 168), ('총리', 168), ('이스라엘', 167), ('첫', 165), ('사우디', 154), ('EU', 153), ('미국', 143), ('日', 142), ('英', 132), ('러시아', 130)]\n",
      "하위 20개\n",
      "[('왓츠앱稅', 1), ('230원에', 1), ('민심…총리사퇴로', 1), ('이어져종합2보', 1), ('고성장', 1), ('지속…2분기', 1), ('6.71%', 1), ('한국전', 1), ('기념식…참전용사', 1), ('30억', 1), ('예산팽창에', 1), ('재정건전성', 1), ('우려…내년에', 1), ('장기채무', 1), ('민중가수', 1), ('도피', 1), ('선다', 1), ('온라인으로', 1), ('비자신청', 1), ('마비시킨', 1)]\n",
      "===== 스포츠 =====\n",
      "19230\n",
      "상위 20개\n",
      "[('감독', 622), ('첫', 339), ('월드컵', 330), ('류현진', 304), ('꺾고', 298), ('프로농구', 262), ('시즌', 246), ('아시안게임', 239), ('MLB', 231), ('연속', 214), ('...', 205), ('손흥민', 196), ('SK', 187), ('만에', 183), ('NBA', 173), ('여자농구', 152), ('홈런', 138), ('경기', 132), ('선수', 131), ('한국', 129)]\n",
      "하위 20개\n",
      "[('전초기지', 1), ('레오강', 1), ('입성종합', 1), ('쐐기타…kt', 1), ('승부욕', 1), ('거칠게', 1), ('해야…나부터', 1), ('포효한', 1), ('유지한...', 1), ('보러', 1), ('설욕할까…이재영', 1), ('KIA행…기회', 1), ('반민특위', 1), ('프로스포츠', 1), ('커밍아웃', 1), ('2022', 1), ('항저우로의', 1), ('채프먼·헤이더', 1), ('구원투수상', 1), ('리거', 1)]\n",
      "===== 정치 =====\n",
      "21117\n",
      "상위 20개\n",
      "[('北', 692), ('朴대통령', 616), ('대통령', 433), ('문', 349), ('靑', 269), ('김정은', 250), ('與', 193), ('북한', 182), ('정부', 167), ('문대통령', 158), ('한국당', 158), ('국회', 156), ('여야', 155), ('민주', 143), ('평양정상회담', 123), ('것', 122), ('첫', 119), ('더민주', 109), ('오늘', 100), ('등', 98)]\n",
      "하위 20개\n",
      "[('당현실', 1), ('봐야…물러나는게', 1), ('좋다종합', 1), ('루브르', 1), ('박물관', 1), ('십리대숲·재래시장', 1), ('방문…휴가', 1), ('단임제로', 1), ('지속가능한', 1), ('어렵다속보', 1), ('일정재개…여야', 1), ('환담도', 1), ('에티오피아', 1), ('입맛에', 1), ('맞아요…현지인들', 1), ('통해요', 1), ('경우도', 1), ('국가기능', 1), ('안정적', 1), ('유지속보', 1)]\n"
     ]
    }
   ],
   "source": [
    "num2label = {\n",
    "    k: v for k, v in enumerate(['IT과학', '경제', '사회', '생활문화', '세계', '스포츠', '정치'])\n",
    "}\n",
    "\n",
    "for target in range(7):\n",
    "    print(\"=\"*5, num2label[target], \"=\"*5)\n",
    "    view_df = train_df[train_df['target'] == target]\n",
    "\n",
    "    arr = []\n",
    "    for row in view_df['text'].to_list():\n",
    "        arr.extend(row.split())\n",
    "\n",
    "    counter = Counter(arr)\n",
    "    print(len(counter))\n",
    "    print(\"상위 20개\")\n",
    "    print(counter.most_common(20))\n",
    "    print(\"하위 20개\")\n",
    "    print(sorted(counter.items(), key=lambda x: x[1])[:20])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. 레이블 잘못 지정된 거 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110534, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_hub = pd.read_csv('../data/ai_hub_original.csv')\n",
    "ai_hub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    14164\n",
       "1    19867\n",
       "2    39873\n",
       "3    19844\n",
       "4     5470\n",
       "5     4642\n",
       "6     6674\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_hub['target'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "ai_hub['text'] = ai_hub['text'].apply(lambda x: re.sub('[,‘’“”()/\\\"\\'<>\\[\\]]','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_026 = ai_hub[ai_hub['target'] == 0].index\n",
    "idx_520 = ai_hub[ai_hub['target'] == 5].index\n",
    "idx_625 = ai_hub[ai_hub['target'] == 6].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_hub.loc[idx_026, \"target\"] = 6\n",
    "ai_hub.loc[idx_520, \"target\"] = 0\n",
    "ai_hub.loc[idx_625, \"target\"] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0     4642\n",
       "1    19867\n",
       "2    39873\n",
       "3    19844\n",
       "4     5470\n",
       "5     6674\n",
       "6    14164\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_hub['target'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_hub.to_csv('../data/ai_hub_original_v2.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. 종합 속보 이보 빈도 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train_spelling_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "종합    4463\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['text'].str.extract('(종합)').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "속보    186\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['text'].str.extract('(속보)').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "이보    3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['text'].str.extract('(이보)').value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. add label token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             생활문화 [SEP] 유튜브 내달 2일까지 크리에이터 지원 공간 운영\n",
       "1                생활문화 [SEP] 어버이날 맑다가 흐려져…남부지방 옅은 황사\n",
       "2              사회 [SEP] 내년부터 국가RD 평가 때 논문건수는 반영 않는다\n",
       "3          사회 [SEP] 김명자 신임 과총 회장 원로와 젊은 과학자 지혜 모을 것\n",
       "4         생활문화 [SEP] 회색인간 작가 김동식 양심고백 등 새 소설집 2권 출간\n",
       "                            ...                    \n",
       "45673         세계 [SEP] 사우디 아람코 주요 석유시설·유전 드론 공격에 화재\n",
       "45674      스포츠 [SEP] 박기원 감독 눈치 보지 말고…비예나 눈치 본 건 아닌데\n",
       "45675    스포츠 [SEP] 아시안게임 첫 경기 앞둔 라건아 인도네시아 팬이라도 ...\n",
       "45676        세계 [SEP] 트럼프 미중 무역협상 1단계 합의 서명식 가질 것종합\n",
       "45677    스포츠 [SEP] 극적 역전승 도로공사 GS칼텍스 꺾고 2년 연속 챔프...\n",
       "Length: 45678, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "label2num = {\n",
    "    k: v for k, v in enumerate(['IT과학', '경제', '사회', '생활문화', '세계', '스포츠', '정치'])\n",
    "}\n",
    "\n",
    "train_df['target'].apply(lambda x: label2num[x]) + \" [SEP] \" + train_df['text']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. ai hub 데이터셋 분포 맞게 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train_spelling_v2_label_v1.csv')\n",
    "ai_hub = pd.read_csv('../data/ai_hub_original_final_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    5538\n",
       "1    5960\n",
       "2    4939\n",
       "3    5795\n",
       "4    8227\n",
       "5    7835\n",
       "6    7384\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['target'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0     4282\n",
       "1     9833\n",
       "2    54078\n",
       "3    17712\n",
       "4     6223\n",
       "5     6801\n",
       "6    11605\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_hub['target'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0     9820\n",
       "1    15793\n",
       "2    59017\n",
       "3    23507\n",
       "4    14450\n",
       "5    14636\n",
       "6    18989\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_hub['target'].value_counts().sort_index() + train_df['target'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4462\n",
       "1    4040\n",
       "2    5061\n",
       "3    4205\n",
       "4    1773\n",
       "5    2165\n",
       "6    2616\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10000 - train_df['target'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0     7747\n",
       "1    18544\n",
       "2    40415\n",
       "3    17599\n",
       "4    13824\n",
       "5    17849\n",
       "6    16296\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_2020 = pd.read_csv(\"../data/cleaned_2020_labeladdLM_v1.csv\")\n",
    "\n",
    "cleaned_2020['target'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    13285\n",
       "1    24504\n",
       "2    45354\n",
       "3    23394\n",
       "4    22051\n",
       "5    25684\n",
       "6    23680\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['target'].value_counts().sort_index() + cleaned_2020['target'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24142, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance_ai_hub = ai_hub[ai_hub['target'] == 0]\n",
    "\n",
    "# ai hub 데이터셋에서 분포에 맞게 데이터 추출하기\n",
    "for target, num in enumerate((10000 - train_df['target'].value_counts().sort_index())[1:]):\n",
    "    view_df = ai_hub[ai_hub['target'] == target+1].sample(n=num, random_state=456)\n",
    "\n",
    "    balance_ai_hub = pd.concat([balance_ai_hub, view_df], axis=0)\n",
    "\n",
    "balance_ai_hub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0     9820\n",
       "1    10000\n",
       "2    10000\n",
       "3    10000\n",
       "4    10000\n",
       "5    10000\n",
       "6    10000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['target'].value_counts() + balance_ai_hub['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_ai_hub.to_csv('../data/ai_hub_original_final_v1_balance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57607, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance_cleaned_2020 = cleaned_2020[cleaned_2020['target'] == 0]\n",
    "\n",
    "# ai hub 데이터셋에서 분포에 맞게 데이터 추출하기\n",
    "for target, num in enumerate((15000 - train_df['target'].value_counts().sort_index())[1:]):\n",
    "    view_df = cleaned_2020[cleaned_2020['target'] == target+1].sample(n=num, random_state=456)\n",
    "\n",
    "    balance_cleaned_2020 = pd.concat([balance_cleaned_2020, view_df], axis=0)\n",
    "\n",
    "balance_cleaned_2020.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    13285\n",
       "1    15000\n",
       "2    15000\n",
       "3    15000\n",
       "4    15000\n",
       "5    15000\n",
       "6    15000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['target'].value_counts() + balance_cleaned_2020['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_cleaned_2020.to_csv('../data/cleaned_2020_labeladdLM_v1_balance.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. NNST 라이브러리 사용해 네이버 뉴스 긁어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nnst in /opt/conda/lib/python3.8/site-packages (0.0.0.5)\n",
      "Requirement already satisfied: bs4>=0.0.1 in /opt/conda/lib/python3.8/site-packages (from nnst) (0.0.1)\n",
      "Requirement already satisfied: nose>=1.3.7 in /opt/conda/lib/python3.8/site-packages (from nnst) (1.3.7)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.8/site-packages (from nnst) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /opt/conda/lib/python3.8/site-packages (from nnst) (2.0.1)\n",
      "Requirement already satisfied: requests>=2.19.1 in /opt/conda/lib/python3.8/site-packages (from nnst) (2.30.0)\n",
      "Requirement already satisfied: urllib3>=1.23 in /opt/conda/lib/python3.8/site-packages (from nnst) (1.26.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.8/site-packages (from bs4>=0.0.1->nnst) (4.9.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/ml/.local/lib/python3.8/site-packages (from pandas>=0.23.4->nnst) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23.4->nnst) (2020.5)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23.4->nnst) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.1->nnst) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.1->nnst) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.1->nnst) (2023.5.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/ml/.local/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas>=0.23.4->nnst) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.8/site-packages (from beautifulsoup4->bs4>=0.0.1->nnst) (2.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nnst"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. en2ko 데이터 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "en2ko_0_7830 = pd.read_csv('../data/en2ko/en2ko_0_7830.csv')\n",
    "en2ko_9136_18271 = pd.read_csv('../data/en2ko/en2ko_9136_18271.csv')\n",
    "en2ko_18272_27408 = pd.read_csv('../data/en2ko/en2ko_18272_27408.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7831, 8), (9135, 8), (9136, 8))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en2ko_0_7830.shape, en2ko_9136_18271.shape, en2ko_18272_27408.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26102, 8), 26102)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en2ko_df = pd.concat([en2ko_0_7830, en2ko_9136_18271], axis=0)\n",
    "en2ko_df = pd.concat([en2ko_df, en2ko_18272_27408], axis=0)\n",
    "en2ko_df.shape, 7831 + 9135 + 9136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'ID', 'text', 'target', 'url', 'date', 'ko2en', 'en2ko'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en2ko_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "en2ko_df['text'] = en2ko_df['en2ko']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26102, 8)\n",
      "(24234, 8)\n"
     ]
    }
   ],
   "source": [
    "print(en2ko_df.shape)\n",
    "en2ko_df = en2ko_df.dropna(subset='en2ko')\n",
    "print(en2ko_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "en2ko_df[['ID', 'text', 'target']].to_csv('../data/en2ko.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
